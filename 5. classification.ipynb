{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define class of transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "class TransferLearningYOLOv5sNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferLearningYOLOv5sNetwork, self).__init__()\n",
    "\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "        \n",
    "        # load a pre-trained model for the feature extractor\n",
    "        self.feature_extractor = nn.Sequential(*list(model.children())[:-1]).eval()\n",
    "        self.fc = nn.Linear(self.classifier[-1].in_features, 7)\n",
    "\n",
    "        # fix the pre-trained network\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.feature_extractor(images)\n",
    "        x = torch.flatten(features, 1)\n",
    "        outputs = self.fc(x)\n",
    "        return features, outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning and traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Define transforms for image preprocessing\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((1920, 1080)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = ImageFolder(root='./dataset/train/', transform=transforms)\n",
    "val_dataset = ImageFolder(root='./dataset/val/', transform=transforms)\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Load pre-trained model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object\n",
    "pretrained_model = TransferLearningYOLOv5sNetwork().to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pretrained_model.parameters(), lr=0.12)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(100):\n",
    "    # Train for one epoch\n",
    "    pretrained_model.train()\n",
    "    for images, targets in train_loader:\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = pretrained_model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Evaluate on validation set\n",
    "    pretrained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for images, targets in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            outputs = pretrained_model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item() * len(images)\n",
    "        avg_loss = total_loss / len(val_dataset)\n",
    "        print(f\"Epoch {epoch+1}, Validation loss: {avg_loss:.4f}\")\n",
    "        \n",
    "torch.save(pretrained_model.to(device).state_dict(), './transfer_learned_weights.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define compute_mAP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.ops import box_iou, box_convert\n",
    "\n",
    "def compute_mAP(all_boxes, all_labels, all_scores, class_names, iou_threshold=0.5, score_threshold=0.5):\n",
    "    num_classes = len(class_names)\n",
    "    ap_per_class = {}\n",
    "    for class_idx in range(num_classes):\n",
    "        class_name = class_names[class_idx]\n",
    "        gt_boxes = []\n",
    "        gt_labels = []\n",
    "        det_boxes = []\n",
    "        det_labels = []\n",
    "        det_scores = []\n",
    "        for boxes, labels, scores in zip(all_boxes, all_labels, all_scores):\n",
    "            mask = labels == class_idx\n",
    "            gt_boxes.append(boxes[mask])\n",
    "            gt_labels.append(labels[mask])\n",
    "            det_boxes.append(boxes[~mask])\n",
    "            det_labels.append(labels[~mask])\n",
    "            det_scores.append(scores[~mask])\n",
    "\n",
    "        gt_boxes = np.concatenate(gt_boxes, axis=0)\n",
    "        gt_labels = np.concatenate(gt_labels, axis=0)\n",
    "        det_boxes = np.concatenate(det_boxes, axis=0)\n",
    "        det_labels = np.concatenate(det_labels, axis=0)\n",
    "        det_scores = np.concatenate(det_scores, axis=0)\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        gt_boxes = box_convert(gt_boxes, in_fmt='xywh', out_fmt='xyxy')\n",
    "        det_boxes = box_convert(det_boxes, in_fmt='cxcywh', out_fmt='xyxy')\n",
    "\n",
    "        # Compute iou matrix\n",
    "        iou_matrix = box_iou(gt_boxes, det_boxes)\n",
    "\n",
    "        # Apply score and iou threshold\n",
    "        mask = (iou_matrix > iou_threshold) & (det_scores > score_threshold)\n",
    "        det_boxes = det_boxes[mask]\n",
    "        det_labels = det_labels[mask]\n",
    "        det_scores = det_scores[mask]\n",
    "\n",
    "        # Compute precision and recall\n",
    "        num_gt_boxes = gt_boxes.shape[0]\n",
    "        num_det_boxes = det_boxes.shape[0]\n",
    "        tp = np.zeros(num_det_boxes, dtype=bool)\n",
    "        fp = np.zeros(num_det_boxes, dtype=bool)\n",
    "        for i in range(num_det_boxes):\n",
    "            overlaps = iou_matrix[:, i]\n",
    "            gt_idx = overlaps.argmax()\n",
    "            iou = overlaps[gt_idx]\n",
    "            if iou >= iou_threshold and gt_labels[gt_idx] == class_idx:\n",
    "                if not tp[i]:\n",
    "                    tp[i] = True\n",
    "                else:\n",
    "                    fp[i] = True\n",
    "            else:\n",
    "                fp[i] = True\n",
    "\n",
    "        tp_cumsum = np.cumsum(tp)\n",
    "        fp_cumsum = np.cumsum(fp)\n",
    "        recall = tp_cumsum / num_gt_boxes\n",
    "        precision = tp_cumsum / (tp_cumsum + fp_cumsum)\n",
    "\n",
    "        # Compute AP using 11-point interpolation\n",
    "        recall_interp = np.linspace(0, 1, 11)\n",
    "        precision_interp = np.interp(recall_interp, recall, precision)\n",
    "        ap = np.mean(precision_interp)\n",
    "\n",
    "        ap_per_class[class_name] = ap\n",
    "\n",
    "    return ap_per_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Load test dataset\n",
    "test_dataset = ImageFolder(root='./dataset/test/', transform=transforms.Compose([\n",
    "    transforms.Resize((1920, 1080)),\n",
    "    transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "# Define dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# Load transfer learned model\n",
    "model = torch.load('./transfer_learned_weights.pt')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test dataset\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    all_boxes = []\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        boxes, labels, scores = model.postprocess(outputs, images.shape[-2:])\n",
    "        all_boxes.append(boxes.cpu().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_scores.append(scores.cpu().numpy())\n",
    "\n",
    "    # Compute mean average precision (mAP) for each class\n",
    "    ap_per_class = compute_mAP(all_boxes, all_labels, all_scores, test_dataset.classes)\n",
    "    mAP = sum(ap_per_class.values()) / len(ap_per_class)\n",
    "    print(f\"Mean Average Precision (mAP): {mAP:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
